{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# change path to be in alpaca_rl_trader for linux\n",
    "#os.chdir('/home/joe/Python/tradingbot/gym/alpaca_rl_trader')\n",
    "\n",
    "# change path to be in alpaca_rl_trader for windows\n",
    "os.chdir('C:/Users/JoeBa/Documents/python/alpaca_rl_trader_Discrete/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_loader import load_data, SplitOption\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming based on symbol(s): X:AVAXUSD\n",
      "X:AAVEUSD: Trimmed 32.13%\n",
      "X:MKRUSD: Trimmed 51.76%\n",
      "X:LTCUSD: Trimmed 41.94%\n",
      "X:ETHUSD: Trimmed 41.91%\n",
      "X:CRVUSD: Trimmed 35.69%\n",
      "X:BCHUSD: Trimmed 42.97%\n",
      "X:LINKUSD: Trimmed 42.37%\n",
      "X:BATUSD: Trimmed 61.30%\n",
      "X:SHIBUSD: Trimmed 3.27%\n",
      "X:BTCUSD: Trimmed 41.91%\n",
      "X:GRTUSD: Trimmed 29.60%\n",
      "X:XTZUSD: Trimmed 47.69%\n",
      "X:UNIUSD: Trimmed 35.95%\n",
      "X:DOTUSD: Trimmed 42.11%\n",
      "X:AVAXUSD: Trimmed 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Get test data\n",
    "data = load_data(\n",
    "    ratio=0.8, split_option=SplitOption.NO_SPLIT, symbols=[], table_name='crypto_data_hourly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preprocessing\n",
    "The first step is to convert your DataFrame into a format that can be used for training the autoencoder. Each stock's data should be transformed into a sequence of fixed-length windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 'price' and 'volume' columns\n",
    "price_column = 'close'  # Replace with your actual price column name\n",
    "volume_column = 'volume'  # Replace with your actual volume column name\n",
    "\n",
    "# Function to create sequences with scaling applied to each sequence\n",
    "def create_sequences(data):\n",
    "    for i in range(len(data)):\n",
    "        # Get the price and volume data for the current row\n",
    "        close = np.log(data[price_column][i]+1)\n",
    "        volume = np.log(data[volume_column][i]+1)\n",
    "        \n",
    "    return np.array([close, volume]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for each stock\n",
    "stock_sequences = {}\n",
    "for ticker in data.keys():\n",
    "    stock_sequences[ticker] = create_sequences(data[ticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first ticker key from the sorted dictionary\n",
    "first_ticker = next(iter(data))\n",
    "length_of_data = len(data[first_ticker]['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10030"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.97714745, 7.14622942])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_sequences[first_ticker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creating the Dataset for Training\n",
    "Once you have the sequences, you can create a dataset that is suitable for training the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# Convert sequences to a single NumPy ndarray\n",
    "all_sequences = np.concatenate([np.array(sequences) for sequences in stock_sequences.values()], axis=0)\n",
    "\n",
    "# Convert the NumPy ndarray to a PyTorch tensor\n",
    "all_sequences = torch.tensor(all_sequences, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 64  # You can adjust this\n",
    "dataset = TensorDataset(all_sequences, all_sequences)  # input and target are the same for autoencoders\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define the Autoencoder\n",
    "Now, define the autoencoder model. You can use the example provided in the previous response or create your own architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TimeSeriesAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeSeriesAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(2, 64),  # Input size: 2 (price and volume), Output size: 64 (adjust as needed)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),  # Output size: 32 (adjust as needed)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),  # Input size: 32, Output size: 64 (mirroring the encoder)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # Input size: 64, Output size: 2 (mirroring the input features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Instantiate the autoencoder\n",
    "autoencoder = TimeSeriesAutoencoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeSeriesAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeSeriesAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv1d(2, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32, 48, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # Additional Pooling Layer\n",
    "        self.additional_pool = nn.MaxPool1d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Conv1d(48, 2, kernel_size=3, padding=1)  # Reduced channel dimensions\n",
    "\n",
    "        # Decoder convolution layers\n",
    "        self.deconv1 = nn.Conv1d(2, 48, kernel_size=3, padding=1)\n",
    "        self.deconv2 = nn.Conv1d(48, 32, kernel_size=3, padding=1)\n",
    "        self.deconv3 = nn.Conv1d(32, 16, kernel_size=3, padding=1)\n",
    "        self.output_layer = nn.Conv1d(16, 2, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.additional_pool(x)\n",
    "        encoded = self.bottleneck(x)  # Compressed representation\n",
    "\n",
    "        # Decode\n",
    "        x = F.interpolate(encoded, scale_factor=2, mode='nearest')\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = F.relu(self.deconv3(x))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        decoded = F.tanh(self.output_layer(x))\n",
    "\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the Autoencoder\n",
    "Finally, train the autoencoder. This involves passing your data through the model and using a loss function (like MSE) to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x30 and 2x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m encoded, decoded \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(decoded, targets)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m, in \u001b[0;36mTimeSeriesAutoencoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 22\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(encoded)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded, decoded\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JoeBa\\Documents\\python\\virtual_environments\\trading_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x30 and 2x64)"
     ]
    }
   ],
   "source": [
    "# Define your autoencoder model\n",
    "autoencoder = TimeSeriesAutoencoder()\n",
    "\n",
    "# Define Loss Function and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0001)\n",
    "\n",
    "# Initialize the best loss value\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 1000  # Number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for data in data_loader:\n",
    "        inputs, targets = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        encoded, decoded = autoencoder(inputs)\n",
    "        loss = criterion(decoded, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss for each epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Save the model if this epoch has the best loss so far\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        torch.save(autoencoder.state_dict(), 'best_autoencoder.pth')\n",
    "        print(f\"Saved better model with loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model (ensure the model class is defined in your script)\n",
    "autoencoder = TimeSeriesAutoencoder()\n",
    "\n",
    "# Load the state dict\n",
    "autoencoder.load_state_dict(torch.load('best_autoencoder.pth'))\n",
    "\n",
    "# If you saved the entire model, you can directly load it (not recommended for large models)\n",
    "# autoencoder = torch.load('full_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, _) in enumerate(data_loader):\n",
    "    print(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training your autoencoder\n",
    "# Example for 50 points of data\n",
    "num_points = 50\n",
    "\n",
    "# Loop through the data loader for 50 points\n",
    "for i, (inputs, _) in enumerate(data_loader):\n",
    "    if i >= num_points:\n",
    "        break\n",
    "    # Get the encoded and decoded output\n",
    "    encoded, decoded = autoencoder(inputs)\n",
    "\n",
    "    # Inverse normalize the decoded output\n",
    "    decoded_np = decoded.detach().numpy() \n",
    "\n",
    "    # Compare with original data\n",
    "    original_np = inputs.detach().numpy()\n",
    "\n",
    "    # Visualization for Price\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(original_np[:, 0], label='Original Price')\n",
    "    plt.plot(decoded_np[:, 0], label='Decoded Price')\n",
    "    plt.title(f'Price Time Series - Original vs. Decoded (Point {i + 1})')\n",
    "    plt.legend()\n",
    "\n",
    "    # Visualization for Volume\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(original_np[:, 1], label='Original Volume')\n",
    "    plt.plot(decoded_np[:, 1], label='Decoded Volume')\n",
    "    plt.title(f'Volume Time Series - Original vs. Decoded (Point {i + 1})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have a batch of data\n",
    "inputs, _ = next(iter(data_loader))\n",
    "inputs = inputs.transpose(1, 2)  # Transposing to [batch_size, 2, 90]\n",
    "\n",
    "# Get the encoded output\n",
    "encoded, _ = autoencoder(inputs)\n",
    "\n",
    "# Shapes\n",
    "original_shape = inputs[0,:,:].shape\n",
    "encoded_shape = encoded[0,:,:].shape\n",
    "\n",
    "# Sizes (total number of elements)\n",
    "original_size = inputs[0,:,:].nelement()\n",
    "encoded_size = encoded[0,:,:].nelement()\n",
    "\n",
    "# Printing shapes and sizes\n",
    "print(f\"Original Shape: {original_shape}, Size: {original_size}\")\n",
    "print(f\"Encoded Shape: {encoded_shape}, Size: {encoded_size}\")\n",
    "\n",
    "# Calculating and printing reduction\n",
    "reduction = (1 - (encoded_size / original_size)) * 100\n",
    "print(f\"Reduction in size: {reduction:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradeEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
